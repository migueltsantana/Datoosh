{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Datoosh","text":""},{"location":"#what-is-it","title":"What is it?","text":"<p> Datoosh  is a Python  tool to help you upload CSV files into SQL databases.</p> <p>It makes use of the multiprocessing library to open multiple connections and insert all data more efficiently.</p> <p>Documentation: https://migueltsantana.github.io/datoosh/</p> <p>Source code: https://github.com/migueltsantana/Datoosh</p>"},{"location":"#project-layout","title":"Project layout","text":"<pre><code>databases/\n    mysql.py        # The MySQL wrapper module.\n    postgresql.py   # The PostgreSQL wrapper module.\n    sqlite.py       # The SQLite wrapper module.\nmain.py             # The main script.\nrequirements.txt    # The pip dependencies of the application.\n</code></pre>"},{"location":"dbms/","title":"Supported DBMS","text":"<ul> <li>MySQL </li> <li>PostgreSQL </li> <li>SQLite </li> </ul>"},{"location":"dbms/#where-is-my-dbms","title":"Where is my DBMS?","text":"<p>This tool is very focused on popular DBMS, at the current time. Nevertheless, you are free to contribute with your favourite DBMS! Just make a pull request with your DBMS and I'll be more than happy to include it in this repository.</p> <p>To start creating the DBMS wrapper for your favourite DBMS, take a look at the existing ones and create one with the same methods.</p> <p>If after your implementation, you are able to upload data to the database, you're good to go!</p> <p>Tip</p> <p>Make sure you maintain the method's signatures as they all need to be the same, across all DBMS. You can make auxiliary methods, as long as you keep them inside one <code>.py</code> file</p>"},{"location":"installation/","title":"Installation","text":""},{"location":"installation/#requirements","title":"Requirements","text":"<ul> <li>Python 3.6+</li> </ul>"},{"location":"installation/#commands","title":"Commands","text":"<ol> <li> <p>Create the virtual environment</p> <p> python3 -m venv venv </p> </li> <li> <p>Activate the virtual environment</p> <p> source venv/bin/activate </p> </li> <li> <p>Install all the dependencies</p> <p> pip install -r requirements.txt Successfully installed all dependencies </p> </li> <li> <p>Done! You're ready to use it! </p> </li> </ol>"},{"location":"options/","title":"CLI Options &amp; Usage","text":"<p>This tool is solely a command-line (CLI) application. Follow the options below to use it correctly.</p>"},{"location":"options/#options","title":"Options","text":"<ul> <li><code>-f</code> / <code>--file</code></li> <li><code>-w</code> / <code>--max-worker-threads</code></li> <li><code>-s</code> / <code>--settings</code></li> <li><code>-d</code> / <code>--delimiter</code></li> </ul>"},{"location":"options/#-f","title":"<code>-f</code>","text":"<p>Required: Yes</p> <p>Alternative flag: <code>--file</code> </p> <p>Description: The CSV file to process</p>"},{"location":"options/#-w","title":"<code>-w</code>","text":"<p>Required: Yes</p> <p>Alternative flag: <code>--max-worker-threads</code></p> <p>Description: The maximum number of concurrent processes to read and process the CSV file</p>"},{"location":"options/#-s","title":"<code>-s</code>","text":"<p>Required: Yes</p> <p>Alternative flag: <code>--settings</code></p> <p>Description: The settings file</p>"},{"location":"options/#-d","title":"<code>-d</code>","text":"<p>Required: No</p> <p>Alternative flag: <code>--delimiter</code></p> <p>Description: The delimiter of the CSV file</p> <p>Default value: <code>,</code></p>"},{"location":"options/#usage","title":"Usage","text":"<p>Make sure the virtual environment is activated!</p> <p>To run this CLI, you will need some dependencies that have been previously installed. If you haven't started your installation, please consider checking Installation. To activate your virtual environment, you just have to make sure you're on the root folder of the project and type <code>source venv/bin/activate</code>.</p> python main.py -w 50 -s settings.yaml -f file.csv Successfully uploaded to the database"},{"location":"settings/","title":"Settings file","text":""},{"location":"settings/#file-definition","title":"File definition","text":"<p>The settings file is provided to the tool with the flag <code>-s</code> (or <code>--settings</code>). This will be a YAML file and you need to use the following structure with this tool:</p> <ul> <li><code>table-name</code>: The name of the table that you want to put the data into.</li> <li> <p><code>columns</code>: The description of the columns.</p> <p>For each column:</p> <ul> <li><code>name</code>: The name of the column.</li> <li> <p><code>type</code>: The type of data.</p> <p>Be careful with the data definition!</p> <p>These data definition types will be used to instantiate a new table. They must be aligned with the DBMS you'll be using.</p> <p>If you want to define a primary key or a unique constraint, this will the correct place to do it.</p> </li> </ul> </li> <li> <p><code>database</code>: The description of the database.</p> <ul> <li><code>type</code>: The type of the DBMS you'll be using (<code>mysql</code>, <code>postgresql</code> or <code>sqlite</code>).</li> <li><code>host</code>: The hostname of the DBMS.</li> <li><code>user</code>: The username to access the DBMS.</li> <li><code>password</code>: The password to access the DBMS.</li> <li><code>name</code>: The name of the database to use.</li> </ul> </li> </ul>"},{"location":"settings/#example-file","title":"Example file","text":"<pre><code>table-name: data\ncolumns:\n  - name: event_place\n    type: VARCHAR(100)\n  - name: event_type\n    type: VARCHAR(100)\n  ...\ndatabase:\n  type: mysql\n  host: localhost\n  user: root\n  password: password\n  name: datoosh\n</code></pre>"},{"location":"why/","title":"Why?","text":"<p>Data is growing faster and faster and exponentially. It has been crucial to process these large amounts of data at record speeds. However, data is often found in many other formats or locations other than a database. Because of this, it's important to ensure that they are housed in these technologies and enable their immediate analysis.</p>"},{"location":"why/#is-there-a-need-for-it","title":"Is there a need for it?","text":"<p>When there is a need to put large amounts of data stored in CSV files, this tool is very useful to get the databases populated in a short time.</p> <p>This tool uses Python's multiprocessing library to slit the file into multiple parts, make connections to the database and parallelize tasks.</p>"}]}